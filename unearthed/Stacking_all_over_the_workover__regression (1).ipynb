{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacking_all_over_the_workover_ regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kqorYLDnz2-"
      },
      "source": [
        "# !mkdir datasets\n",
        "# !unzip '/content/drive/MyDrive/new_hackathon_all_over_worker.zip' -d datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYxznY7BjVAi"
      },
      "source": [
        "# !pip install --upgrade lightgbm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yX0vHuIn-q1"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7_759FdoAyU",
        "outputId": "1b69ca77-1b1f-47e4-bf6c-b546b67e25dd"
      },
      "source": [
        "### Reading train and test datasets\n",
        "well_df      = pd.read_csv('/content/datasets/new_hackathon_all_over_worker/well_details.csv')\n",
        "train_df     = pd.read_csv('/content/datasets/new_hackathon_all_over_worker/public_train.csv')\n",
        "test_df      = pd.read_csv('/content/datasets/new_hackathon_all_over_worker/private_input.csv')\n",
        "well_depth   = pd.read_csv('/content/datasets/new_hackathon_all_over_worker/intake_depth v2.csv')\n",
        "\n",
        "print(f'Shape of train data before removal of future values:- {train_df.shape}')\n",
        "print(f'Shape of test data before removal of future values:- {test_df.shape}')\n",
        "print(f'Shape of well depth before removal of future values:- {well_depth.shape}')\n",
        "print('\\n')\n",
        "\n",
        "## Removig future values from the both train and test data\n",
        "train_df     = train_df.dropna(subset=['PUMP_ID_PHASE'])\n",
        "test_df      = test_df.dropna(subset=['PUMP_ID_PHASE'])\n",
        "well_depth   = well_depth.dropna(subset=['Tubing_Pull_Date'])\n",
        "well_depth   = well_depth[['Well_Number','Intake_Depth']]\n",
        "\n",
        "print(f'Shape of train data after removal of future values:- {train_df.shape}')\n",
        "print(f'Shape of test data after removal of future values:- {test_df.shape}')\n",
        "print(f'Shape of well depth before removal of future values:- {well_depth.shape}')\n",
        "\n",
        "train_df     = train_df.merge(well_df,on=['Well_Number'],how='left')\n",
        "test_df      = test_df.merge(well_df,on=['Well_Number'],how='left')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train data before removal of future values:- (1734579, 17)\n",
            "Shape of test data before removal of future values:- (726517, 15)\n",
            "Shape of well depth before removal of future values:- (3752, 4)\n",
            "\n",
            "\n",
            "Shape of train data after removal of future values:- (1117926, 17)\n",
            "Shape of test data after removal of future values:- (477424, 15)\n",
            "Shape of well depth before removal of future values:- (2552, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7cuagAdB4Ui"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhQmjzQlIHQa"
      },
      "source": [
        "### Creating some extra features based on data understanding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8wcTradoEPt"
      },
      "source": [
        "train_df['Difference_actual_pred_gas']    = train_df['Gas_Capacity']-train_df['Gas_Rate']\n",
        "train_df['Difference_actual_pred_water']  = train_df['Water_Capacity']-train_df['Water_Rate']\n",
        "train_df['Difference_bw_outer_inner']     = train_df['Gas_Pressure']-train_df['Pump_Pressure']\n",
        "\n",
        "test_df['Difference_actual_pred_gas']    = test_df['Gas_Capacity']-test_df['Gas_Rate']\n",
        "test_df['Difference_actual_pred_water']  = test_df['Water_Capacity']-test_df['Water_Rate']\n",
        "test_df['Difference_bw_outer_inner']     = test_df['Gas_Pressure']-test_df['Pump_Pressure']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYe3BSqWwat3"
      },
      "source": [
        "# train_df['Gas_Capacity_Rate']=np.where(train_df['Gas_Rate']!=0,train_df['Gas_Capacity']/train_df['Gas_Rate'],np.NaN)\n",
        "# train_df['Water_Capacity_Rate']=np.where(train_df['Water_Rate']!=0,train_df['Water_Capacity']/train_df['Water_Rate'],np.NaN)\n",
        "# train_df['Gas_Pump_Pressure']=np.where(train_df['Pump_Pressure']!=0,train_df['Gas_Pressure']/train_df['Pump_Pressure'],np.NaN)\n",
        "# train_df['Pump_Pressure_Speed']=np.where(train_df['Pump_Speed']!=0,train_df['Pump_Pressure']/train_df['Pump_Speed'],np.NaN)\n",
        "\n",
        "# test_df['Gas_Capacity_Rate']=np.where(test_df['Gas_Rate']!=0,test_df['Gas_Capacity']/test_df['Gas_Rate'],np.NaN)\n",
        "# test_df['Water_Capacity_Rate']=np.where(test_df['Water_Rate']!=0,test_df['Water_Capacity']/test_df['Water_Rate'],np.NaN)\n",
        "# test_df['Gas_Pump_Pressure']=np.where(test_df['Pump_Pressure']!=0,test_df['Gas_Pressure']/test_df['Pump_Pressure'],np.NaN)\n",
        "# test_df['Pump_Pressure_Speed']=np.where(test_df['Pump_Speed']!=0,test_df['Pump_Pressure']/test_df['Pump_Speed'],np.NaN)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yp48XxxIPaN"
      },
      "source": [
        "## Build Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tqKMQVRoIIs"
      },
      "source": [
        "numerical_aggregation_columns = ['Gas_Rate','Water_Rate','Gas_Capacity','Water_Capacity',\n",
        "                                  'Gas_Pressure','Pump_Pressure','Pump_Speed','Pump_Torque','Pump_Volumetric_Eff',\n",
        "                                  'Downhole_Gauge_Fluid_Level_Above_Sensor','Pump_Torque.1',\n",
        "                                  'Difference_actual_pred_gas','Difference_actual_pred_water','Difference_bw_outer_inner',\n",
        "                                #  'Gas_Capacity_Rate','Water_Capacity_Rate','Gas_Pump_Pressure','Pump_Pressure_Speed'\n",
        "                                ]   \n",
        "batches                       = 5   \n",
        "aggregations                  = ['min','max','mean','std','skew','nunique']     \n",
        "phase2consider                = [5]                        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyDZCbaYoZHh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNBSxC2WtPKz"
      },
      "source": [
        "def compute_slope(y_values):\n",
        "    '''\n",
        "        Computes the slope corresponding to a list (The list is comprised of time-indexed feature values)\n",
        "        If the inpute list is empty, NaN is returned.\n",
        "    '''\n",
        "    try:\n",
        "      z = linregress(list(range(1,len(y_values)+1)), y_values)\n",
        "      return z.slope\n",
        "    except:\n",
        "      return np.nan\n",
        "\n",
        "def compute_mad(y_values):\n",
        "    '''\n",
        "        Computes the mean absolute deviation from the given set of observations.\n",
        "    '''\n",
        "    try:\n",
        "      np.nanmean(np.absolute(y_values - np.nanmean(y_values))) \n",
        "    except:\n",
        "      return np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVYLYEdXb4XX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2BlQbyAoJqJ"
      },
      "source": [
        "def get_phasewise_aggregation(input_column,colname,aggregation,groupby_index):\n",
        "  '''\n",
        "    Performs phasewise mathematical roll-ups to be incorporated as groupby aggregation.\n",
        "    The inputs are :- \n",
        "    input_column   - The column where the aggregation needs to be performed\n",
        "    colname        - The index corresponding to which the groupby is performed for this aggregation\n",
        "    aggregation    - The aggregation name (like mean, std, slope etc)\n",
        "    \n",
        "    The output to this function will be a dictionary having phasewise aggregation results\n",
        "  '''\n",
        "  \n",
        "  count                            = 0\n",
        "  batch_size                       = len(input_column)//batches\n",
        "  phases                           = {}\n",
        "  while count<batches:\n",
        "    \n",
        "    if count!=batches-1:\n",
        "      subset_array                 = input_column[count*batch_size:(count+1)*batch_size]\n",
        "      phase                        = 'phase'\n",
        "    \n",
        "    else:\n",
        "      subset_array                 = input_column[count*batch_size:]\n",
        "      phase                        = 'phase'\n",
        "\n",
        "    subset_array                   = np.array(subset_array)\n",
        "    if count+1 in phase2consider:\n",
        "    \n",
        "      if aggregation == 'skew':\n",
        "        if len(subset_array)<=1:\n",
        "          phases[f'{groupby_index}_{colname}_{phase}_{count+1}_{aggregation}']  = np.nan\n",
        "        else:\n",
        "          try:\n",
        "            phases[f'{groupby_index}_{colname}_{phase}_{count+1}_{aggregation}']  = np.float(skew(subset_array,nan_policy=\"omit\").data)\n",
        "          except:\n",
        "            phases[f'{groupby_index}_{colname}_{phase}_{count+1}_{aggregation}']  = np.float(skew(subset_array,nan_policy=\"omit\"))\n",
        "        \n",
        "      elif aggregation == 'slope':\n",
        "        phases[f'{groupby_index}_{colname}_{phase}_{count+1}_{aggregation}']  = compute_slope(subset_array)\n",
        "      \n",
        "      elif aggregation == 'mad':\n",
        "        phases[f'{groupby_index}_{colname}_{phase}_{count+1}_{aggregation}']  = compute_mad(subset_array)\n",
        "\n",
        "      elif aggregation == 'nunique':\n",
        "        phases[f'{groupby_index}_{colname}_{phase}_{count+1}_{aggregation}']  = len(np.unique(subset_array))\n",
        "\n",
        "      else:\n",
        "        try:\n",
        "          phases[f'{groupby_index}_{colname}_{phase}_{count+1}_{aggregation}']  = eval(f'np.nan{aggregation}')(subset_array)\n",
        "        except:\n",
        "          phases[f'{groupby_index}_{colname}_{phase}_{count+1}_{aggregation}']  = np.nan\n",
        "    count = count+1\n",
        "  \n",
        "  return phases\n",
        "\n",
        "\n",
        "def call_phasewise_results(groupby_index,colname,aggregation,train=True):\n",
        "  '''\n",
        "      Acts as an aggregation wrapper around 'get_phasewise_aggregation' and returns the phasewise aggregated dictionary \n",
        "      and full aggregated dataframe\n",
        "  '''\n",
        "  if train:\n",
        "    needed_df = train_df\n",
        "  else:\n",
        "    needed_df = test_df\n",
        "  grouped_dictionary = needed_df.groupby([groupby_index]).agg({colname:lambda z : get_phasewise_aggregation(z,colname,aggregation,groupby_index)}).reset_index()\n",
        "  phasewise_df       = pd.concat([grouped_dictionary.drop([colname], axis=1), grouped_dictionary[colname].apply(pd.Series)], axis=1)\n",
        "  \n",
        "  if aggregation!='slope':\n",
        "    grouped_df         = needed_df.groupby([groupby_index]).agg({colname:aggregation})\n",
        "  else:\n",
        "    grouped_df         = needed_df.groupby([groupby_index]).agg({colname:lambda z : compute_slope(z)})\n",
        "  grouped_df.columns   = ['Full_data_'+'_'+groupby_index+'_'+colname+'_'+aggregation for colname in grouped_df.columns]\n",
        "  grouped_df           = grouped_df.reset_index()\n",
        "\n",
        "  combdf               = phasewise_df.merge(grouped_df,on=[groupby_index],how='left')\n",
        "\n",
        "  return combdf\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26spMmi2IVy5"
      },
      "source": [
        "## Aggregations based on Pump-ID for train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-SRCqiEwDD0",
        "outputId": "b73572b9-af4e-4da5-df8d-df6833b12169"
      },
      "source": [
        "train_rollups = pd.DataFrame()\n",
        "for cols in numerical_aggregation_columns:\n",
        "  print(f'Aggregations to be performed on Column :- {cols}')\n",
        "  df = pd.DataFrame()\n",
        "  for agg in aggregations:\n",
        "    print(f'Aggregation performed :- {agg}')\n",
        "    if df.shape[0]==0:\n",
        "      df = call_phasewise_results('PUMP_ID_PHASE',cols,agg,True)\n",
        "    else:\n",
        "      df1 = call_phasewise_results('PUMP_ID_PHASE',cols,agg,True)\n",
        "      df = df.merge(df1,on=['PUMP_ID_PHASE'],how='left')\n",
        "      del df1\n",
        "\n",
        "  if train_rollups.shape[0]==0:\n",
        "    train_rollups = df\n",
        "    print(f'Train Data shape {train_rollups.shape}')\n",
        "  else:\n",
        "    train_rollups = train_rollups.merge(df,on=['PUMP_ID_PHASE'],how='left')\n",
        "    print(f'Train Data shape {train_rollups.shape}')\n",
        "  print('-------------------------------------------------------')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aggregations to be performed on Column :- Gas_Rate\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 13)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Water_Rate\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 25)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Gas_Capacity\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 37)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Water_Capacity\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 49)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Gas_Pressure\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 61)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Pressure\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 73)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Speed\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 85)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Torque\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 97)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Volumetric_Eff\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 109)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Downhole_Gauge_Fluid_Level_Above_Sensor\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 121)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Torque.1\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 133)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_actual_pred_gas\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 145)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_actual_pred_water\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 157)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_bw_outer_inner\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (1779, 169)\n",
            "-------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NDlT2LYIac-"
      },
      "source": [
        "## Aggregations based on Well Number for train data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlPEyfRcGgzr",
        "outputId": "5192e44f-cf05-4832-dc29-bd1ee2d1e540"
      },
      "source": [
        "train_rollups_wells = pd.DataFrame()\n",
        "for cols in numerical_aggregation_columns:\n",
        "  print(f'Aggregations to be performed on Column :- {cols}')\n",
        "  df = pd.DataFrame()\n",
        "  for agg in aggregations:\n",
        "    print(f'Aggregation performed :- {agg}')\n",
        "    if df.shape[0]==0:\n",
        "      df = call_phasewise_results('Well_Number',cols,agg,True)\n",
        "    else:\n",
        "      df1 = call_phasewise_results('Well_Number',cols,agg,True)\n",
        "      df = df.merge(df1,on=['Well_Number'],how='left')\n",
        "      del df1\n",
        "  if train_rollups_wells.shape[0]==0:\n",
        "    train_rollups_wells = df\n",
        "    print(f'Train Data shape {train_rollups_wells.shape}')\n",
        "  else:\n",
        "    train_rollups_wells = train_rollups_wells.merge(df,on=['Well_Number'],how='left')\n",
        "    print(f'Train Data shape {train_rollups_wells.shape}')\n",
        "  print('-------------------------------------------------------')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aggregations to be performed on Column :- Gas_Rate\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 13)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Water_Rate\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 25)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Gas_Capacity\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 37)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Water_Capacity\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 49)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Gas_Pressure\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 61)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Pressure\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 73)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Speed\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 85)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Torque\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 97)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Volumetric_Eff\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 109)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Downhole_Gauge_Fluid_Level_Above_Sensor\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 121)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Torque.1\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 133)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_actual_pred_gas\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 145)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_actual_pred_water\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 157)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_bw_outer_inner\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (849, 169)\n",
            "-------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwYGFJVFIfbV"
      },
      "source": [
        "## Aggregations based on Pump ID for test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgytUEB-o1la",
        "outputId": "ed1bbbc4-08e7-4858-a033-57c498c67c94"
      },
      "source": [
        "test_rollups = pd.DataFrame()\n",
        "for cols in numerical_aggregation_columns:\n",
        "  print(f'Aggregations to be performed on Column :- {cols}')\n",
        "  df = pd.DataFrame()\n",
        "  for agg in aggregations:\n",
        "    print(f'Aggregation performed :- {agg}')\n",
        "    if df.shape[0]==0:\n",
        "      df = call_phasewise_results('PUMP_ID_PHASE',cols,agg,False)\n",
        "    else:\n",
        "      df1 = call_phasewise_results('PUMP_ID_PHASE',cols,agg,False)\n",
        "      df = df.merge(df1,on=['PUMP_ID_PHASE'],how='left')\n",
        "      del df1\n",
        "  if test_rollups.shape[0]==0:\n",
        "    test_rollups = df\n",
        "    print(f'Train Data shape {test_rollups.shape}')\n",
        "  else:\n",
        "    test_rollups = test_rollups.merge(df,on=['PUMP_ID_PHASE'],how='left')\n",
        "    print(f'Train Data shape {test_rollups.shape}')\n",
        "  print('-------------------------------------------------------')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aggregations to be performed on Column :- Gas_Rate\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 13)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Water_Rate\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 25)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Gas_Capacity\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 37)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Water_Capacity\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 49)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Gas_Pressure\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 61)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Pressure\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 73)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Speed\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 85)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Torque\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 97)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Volumetric_Eff\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 109)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Downhole_Gauge_Fluid_Level_Above_Sensor\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 121)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Torque.1\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 133)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_actual_pred_gas\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 145)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_actual_pred_water\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 157)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_bw_outer_inner\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (819, 169)\n",
            "-------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugYxMotnIi1T"
      },
      "source": [
        "## Aggregations based on Well Number for test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldb0WNx1HlJN",
        "outputId": "c3c9a1f8-b835-4bf9-9cd5-ef9b5679c7d4"
      },
      "source": [
        "test_rollups_wells = pd.DataFrame()\n",
        "for cols in numerical_aggregation_columns:\n",
        "  print(f'Aggregations to be performed on Column :- {cols}')\n",
        "  df = pd.DataFrame()\n",
        "  for agg in aggregations:\n",
        "    print(f'Aggregation performed :- {agg}')\n",
        "    if df.shape[0]==0:\n",
        "      df = call_phasewise_results('Well_Number',cols,agg,False)\n",
        "    else:\n",
        "      df1 = call_phasewise_results('Well_Number',cols,agg,False)\n",
        "      df = df.merge(df1,on=['Well_Number'],how='left')\n",
        "      del df1\n",
        "  if test_rollups_wells.shape[0]==0:\n",
        "    test_rollups_wells = df\n",
        "    print(f'Train Data shape {test_rollups_wells.shape}')\n",
        "  else:\n",
        "    test_rollups_wells = test_rollups_wells.merge(df,on=['Well_Number'],how='left')\n",
        "    print(f'Train Data shape {test_rollups_wells.shape}')\n",
        "  print('-------------------------------------------------------')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aggregations to be performed on Column :- Gas_Rate\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 13)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Water_Rate\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 25)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Gas_Capacity\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 37)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Water_Capacity\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 49)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Gas_Pressure\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 61)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Pressure\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 73)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Speed\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 85)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Torque\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 97)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Volumetric_Eff\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 109)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Downhole_Gauge_Fluid_Level_Above_Sensor\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 121)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Pump_Torque.1\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 133)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_actual_pred_gas\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 145)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_actual_pred_water\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 157)\n",
            "-------------------------------------------------------\n",
            "Aggregations to be performed on Column :- Difference_bw_outer_inner\n",
            "Aggregation performed :- min\n",
            "Aggregation performed :- max\n",
            "Aggregation performed :- mean\n",
            "Aggregation performed :- std\n",
            "Aggregation performed :- skew\n",
            "Aggregation performed :- nunique\n",
            "Train Data shape (363, 169)\n",
            "-------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwtnStLBInlw"
      },
      "source": [
        "## Merging rolled-up dataframes to one dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25sdIcF1ESi-",
        "outputId": "a727dfeb-22fb-4710-e303-31e24a844cc9"
      },
      "source": [
        "count = 0 \n",
        "for aggs in aggregations:\n",
        "  print(f'Aggregation on :- {aggs}')\n",
        "  if count==0:\n",
        "    df         = well_depth.groupby('Well_Number').agg({'Intake_Depth':aggs})\n",
        "    df.columns = [aggs+'_'+colname for colname in df.columns]\n",
        "    df         = df.reset_index()\n",
        "\n",
        "  else:\n",
        "    if aggs!='slope':\n",
        "      df1         = well_depth.groupby('Well_Number').agg({'Intake_Depth':aggs})\n",
        "      df1.columns = [aggs+'_'+colname for colname in df1.columns]\n",
        "      df1         = df1.reset_index()\n",
        "\n",
        "      df  = df.merge(df1,on=['Well_Number'],how='left')\n",
        "  count = count+1\n",
        "\n",
        "well_depth_df = df\n",
        "print('Well_depth Aggregation data shape:- ',well_depth_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aggregation on :- min\n",
            "Aggregation on :- max\n",
            "Aggregation on :- mean\n",
            "Aggregation on :- std\n",
            "Aggregation on :- skew\n",
            "Aggregation on :- nunique\n",
            "Well_depth Aggregation data shape:-  (1226, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO12Me3pGNfR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxsGkSWqWGUS"
      },
      "source": [
        "## Creation of final train and test dataset to be used for predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rihpsJThrrig",
        "outputId": "64502073-a5ee-4360-cf0e-70ede50fa0a1"
      },
      "source": [
        "train_well_info = train_df[['PUMP_ID_PHASE','Well_Number','Volumetric_Capacity','HR','Date']].dropna().drop_duplicates(subset=['PUMP_ID_PHASE'])\n",
        "test_well_info  = test_df[['PUMP_ID_PHASE','Well_Number','Date']].dropna().drop_duplicates(subset=['PUMP_ID_PHASE'])\n",
        "\n",
        "train_data = train_rollups.merge(train_well_info,on=['PUMP_ID_PHASE'],how='left')\n",
        "train_data = train_data.merge(well_df,on=['Well_Number'],how='left')\n",
        "train_data = train_data.merge(train_rollups_wells,on=['Well_Number'],how='left')\n",
        "\n",
        "test_data = test_rollups.merge(test_well_info,on=['PUMP_ID_PHASE'],how='left')\n",
        "test_data = test_data.merge(well_df,on=['Well_Number'],how='left')\n",
        "test_data = test_data.merge(test_rollups_wells,on=['Well_Number'],how='left')\n",
        "\n",
        "\n",
        "train_data = train_data.merge(well_depth_df,on=['Well_Number'],how='left')\n",
        "test_data  = test_data.merge(well_depth_df,on=['Well_Number'],how='left')\n",
        "\n",
        "print(train_data.shape,test_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1779, 352) (819, 350)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqrS5usRSzV0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7FeFljhlKm5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebx-rWJFIxIW"
      },
      "source": [
        "## Saving the datasets to be used for model training part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3EzZqo1rrlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470d98da-54ee-4af6-fe3d-1af73bb1ac4e"
      },
      "source": [
        "# train_data.to_csv('/content/drive/MyDrive/all_over_worker/train_data.csv',index=False)\n",
        "# print('Train written')\n",
        "# test_data.to_csv('/content/drive/MyDrive/all_over_worker/test_data.csv',index=False)\n",
        "# print('test written')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train written\n",
            "test written\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG8ans0FNo58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62fbc117-c3a0-4938-c9e0-ef55001d1f3c"
      },
      "source": [
        "1+2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrOdZHllxQYR"
      },
      "source": [
        "# Stacking Regression models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inpcbP4cRX4i"
      },
      "source": [
        "## Regression model 1  on the trained dataset (lightgbm model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQLr7H1rpvUF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import *\n",
        "import lightgbm as lgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vub3SiYpRo6p",
        "outputId": "0bd879a2-20d9-4374-91da-7c86a886b7f4"
      },
      "source": [
        "train_df = train_data.copy()\n",
        "test_df  = test_data.copy()\n",
        "\n",
        "cols2drop = ['PUMP_ID_PHASE','Date','Well_Number','Completion_Type']\n",
        "target_y  = train_df['Volumetric_Capacity'].values\n",
        "train_df  = train_df.drop(cols2drop+['HR','Volumetric_Capacity'],axis=1)\n",
        "test_df   = test_df.drop(cols2drop,axis=1)\n",
        "\n",
        "a         = train_df[train_df.columns].isnull().sum()/train_df.shape[0]\n",
        "cols      = a[a<=0.6].index.tolist()\n",
        "train_df  = train_df[cols]\n",
        "test_df   = test_df[cols]\n",
        "print(train_df.shape,test_df.shape)\n",
        "\n",
        "\n",
        "#### This segment will be used only if we want to make sure the output corresponds to \n",
        "#### a fixed set of volumetric capacity as given in the train data.\n",
        "\n",
        "unique_vals_target = list(set(target_y))\n",
        "def get_nearest_value_possible(value):\n",
        "  '''\n",
        "      Getting target corresponding to nearest value.\n",
        "  '''\n",
        "  abs_distance_dict = {}\n",
        "  for vals in unique_vals_target:\n",
        "    abs_distance_dict[vals] = np.abs(value-vals)\n",
        "  return min(abs_distance_dict, key=abs_distance_dict.get)\n",
        "\n",
        "train     = train_df.values\n",
        "test      = test_df.values\n",
        "train_y   = target_y\n",
        "\n",
        "oof_pred_1               = np.zeros((len(train), ))\n",
        "oof_pred_nearest_1       = np.zeros((len(train), ))\n",
        "y_pred_1                 = np.zeros((len(test), ))\n",
        "n_splits                 = 20\n",
        "kf                       = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (tr_ind, val_ind) in enumerate(kf.split(train, train_y)):\n",
        "  X_train, X_val     = train[tr_ind], train[val_ind]\n",
        "  y_train, y_val     = train_y[tr_ind], train_y[val_ind]\n",
        "\n",
        "  model  = lgb.LGBMRegressor(random_state=42,reg_lambda=4,n_estimators=85,learning_rate=0.1,min_split_gain=0.7)\n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        "  \n",
        "  val_pred_1                  = model.predict(X_val)\n",
        "  val_pred_nearest_1          = [get_nearest_value_possible(val) for val in val_pred_1]\n",
        "  oof_pred_1[val_ind]         = val_pred_1\n",
        "  oof_pred_nearest_1[val_ind] = val_pred_nearest_1\n",
        "\n",
        "\n",
        "  print('MAE(actual):- ',mean_absolute_error(y_val,val_pred_1),' fold ',fold+1)\n",
        "  print('MAE(nearest):- ',mean_absolute_error(y_val,val_pred_nearest_1),' fold ',fold+1)\n",
        "  print('\\n')\n",
        "  \n",
        "  y_pred_1 += model.predict(test) / (n_splits)\n",
        "\n",
        "print('OOF MAE(actual):- ',(mean_absolute_error(train_y,oof_pred_1)))\n",
        "print('OOF MAE(nearest):- ',(mean_absolute_error(train_y,oof_pred_nearest_1)))\n",
        "y_pred_1_nearest                      = [get_nearest_value_possible(val) for val in y_pred_1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1779, 310) (819, 310)\n",
            "MAE(actual):-  11.02164031109445  fold  1\n",
            "MAE(nearest):-  11.07865168539326  fold  1\n",
            "\n",
            "\n",
            "MAE(actual):-  11.198847102819606  fold  2\n",
            "MAE(nearest):-  11.101123595505618  fold  2\n",
            "\n",
            "\n",
            "MAE(actual):-  10.700184052522097  fold  3\n",
            "MAE(nearest):-  10.584269662921349  fold  3\n",
            "\n",
            "\n",
            "MAE(actual):-  11.431109266763498  fold  4\n",
            "MAE(nearest):-  11.292134831460674  fold  4\n",
            "\n",
            "\n",
            "MAE(actual):-  9.602636503146465  fold  5\n",
            "MAE(nearest):-  9.337078651685394  fold  5\n",
            "\n",
            "\n",
            "MAE(actual):-  8.34788728063881  fold  6\n",
            "MAE(nearest):-  8.247191011235955  fold  6\n",
            "\n",
            "\n",
            "MAE(actual):-  13.131982334304656  fold  7\n",
            "MAE(nearest):-  13.067415730337078  fold  7\n",
            "\n",
            "\n",
            "MAE(actual):-  10.062869525428514  fold  8\n",
            "MAE(nearest):-  9.741573033707866  fold  8\n",
            "\n",
            "\n",
            "MAE(actual):-  10.191282941508655  fold  9\n",
            "MAE(nearest):-  10.280898876404494  fold  9\n",
            "\n",
            "\n",
            "MAE(actual):-  10.154863443605931  fold  10\n",
            "MAE(nearest):-  10.044943820224718  fold  10\n",
            "\n",
            "\n",
            "MAE(actual):-  11.323018904758401  fold  11\n",
            "MAE(nearest):-  11.617977528089888  fold  11\n",
            "\n",
            "\n",
            "MAE(actual):-  12.147984599083541  fold  12\n",
            "MAE(nearest):-  11.696629213483146  fold  12\n",
            "\n",
            "\n",
            "MAE(actual):-  8.494182371873018  fold  13\n",
            "MAE(nearest):-  8.539325842696629  fold  13\n",
            "\n",
            "\n",
            "MAE(actual):-  10.992565533651351  fold  14\n",
            "MAE(nearest):-  10.617977528089888  fold  14\n",
            "\n",
            "\n",
            "MAE(actual):-  8.980697712245906  fold  15\n",
            "MAE(nearest):-  8.797752808988765  fold  15\n",
            "\n",
            "\n",
            "MAE(actual):-  8.882178918478294  fold  16\n",
            "MAE(nearest):-  8.651685393258427  fold  16\n",
            "\n",
            "\n",
            "MAE(actual):-  9.026357384485493  fold  17\n",
            "MAE(nearest):-  8.606741573033707  fold  17\n",
            "\n",
            "\n",
            "MAE(actual):-  10.082367549755428  fold  18\n",
            "MAE(nearest):-  9.820224719101123  fold  18\n",
            "\n",
            "\n",
            "MAE(actual):-  11.633992409025707  fold  19\n",
            "MAE(nearest):-  11.629213483146067  fold  19\n",
            "\n",
            "\n",
            "MAE(actual):-  9.206669769498188  fold  20\n",
            "MAE(nearest):-  8.829545454545455  fold  20\n",
            "\n",
            "\n",
            "OOF MAE(actual):-  10.331297709183662\n",
            "OOF MAE(nearest):-  10.179876335019674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJKLCAO7ws2d"
      },
      "source": [
        "## Model 2 for Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH7rxRMjUlaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c6652d-4307-41e1-9ee1-2abb779e21a0"
      },
      "source": [
        "train_df = train_data.copy()\n",
        "test_df  = test_data.copy()\n",
        "\n",
        "cols2drop = ['PUMP_ID_PHASE','Date','Well_Number','Completion_Type']\n",
        "target_y  = train_df['Volumetric_Capacity'].values\n",
        "train_df  = train_df.drop(cols2drop+['HR','Volumetric_Capacity'],axis=1)\n",
        "test_df   = test_df.drop(cols2drop,axis=1)\n",
        "\n",
        "a         = train_df[train_df.columns].isnull().sum()/train_df.shape[0]\n",
        "cols      = a[a<=0.6].index.tolist()\n",
        "train_df  = train_df[cols]\n",
        "test_df   = test_df[cols]\n",
        "print(train_df.shape,test_df.shape)\n",
        "\n",
        "\n",
        "#### This segment will be used only if we want to make sure the output corresponds to \n",
        "#### a fixed set of volumetric capacity as given in the train data.\n",
        "\n",
        "unique_vals_target = list(set(target_y))\n",
        "def get_nearest_value_possible(value):\n",
        "  '''\n",
        "      Getting target corresponding to nearest value.\n",
        "  '''\n",
        "  abs_distance_dict = {}\n",
        "  for vals in unique_vals_target:\n",
        "    abs_distance_dict[vals] = np.abs(value-vals)\n",
        "  return min(abs_distance_dict, key=abs_distance_dict.get)\n",
        "\n",
        "train     = train_df.values\n",
        "test      = test_df.values\n",
        "train_y   = target_y\n",
        "\n",
        "oof_pred_2               = np.zeros((len(train), ))\n",
        "oof_pred_nearest_2       = np.zeros((len(train), ))\n",
        "y_pred_2                 = np.zeros((len(test), ))\n",
        "n_splits                 = 25\n",
        "kf                       = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (tr_ind, val_ind) in enumerate(kf.split(train, train_y)):\n",
        "  X_train, X_val     = train[tr_ind], train[val_ind]\n",
        "  y_train, y_val     = train_y[tr_ind], train_y[val_ind]\n",
        "\n",
        "  model  = lgb.LGBMRegressor(random_state=42,reg_lambda=4,n_estimators=90,learning_rate=0.1)\n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        "  \n",
        "  val_pred_2                  = model.predict(X_val)\n",
        "  val_pred_nearest_2          = [get_nearest_value_possible(val) for val in val_pred_2]\n",
        "  oof_pred_2[val_ind]         = val_pred_2\n",
        "  oof_pred_nearest_2[val_ind] = val_pred_nearest_2\n",
        "\n",
        "\n",
        "  print('MAE(actual):- ',mean_absolute_error(y_val,val_pred_2),' fold ',fold+1)\n",
        "  print('MAE(nearest):- ',mean_absolute_error(y_val,val_pred_nearest_2),' fold ',fold+1)\n",
        "  print('\\n')\n",
        "  \n",
        "  y_pred_2 += model.predict(test) / (n_splits)\n",
        "\n",
        "print('OOF MAE(actual):- ',(mean_absolute_error(train_y,oof_pred_2)))\n",
        "print('OOF MAE(nearest):- ',(mean_absolute_error(train_y,oof_pred_nearest_2)))\n",
        "y_pred_2_nearest                      = [get_nearest_value_possible(val) for val in y_pred_2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1779, 310) (819, 310)\n",
            "MAE(actual):-  10.664258194497632  fold  1\n",
            "MAE(nearest):-  10.541666666666666  fold  1\n",
            "\n",
            "\n",
            "MAE(actual):-  11.003884521159746  fold  2\n",
            "MAE(nearest):-  11.097222222222221  fold  2\n",
            "\n",
            "\n",
            "MAE(actual):-  10.815009328989238  fold  3\n",
            "MAE(nearest):-  11.01388888888889  fold  3\n",
            "\n",
            "\n",
            "MAE(actual):-  10.998950601239937  fold  4\n",
            "MAE(nearest):-  10.88888888888889  fold  4\n",
            "\n",
            "\n",
            "MAE(actual):-  10.87031560838809  fold  5\n",
            "MAE(nearest):-  10.619718309859154  fold  5\n",
            "\n",
            "\n",
            "MAE(actual):-  8.961160682627824  fold  6\n",
            "MAE(nearest):-  8.816901408450704  fold  6\n",
            "\n",
            "\n",
            "MAE(actual):-  8.489178409074842  fold  7\n",
            "MAE(nearest):-  8.76056338028169  fold  7\n",
            "\n",
            "\n",
            "MAE(actual):-  10.192022909362448  fold  8\n",
            "MAE(nearest):-  10.014084507042254  fold  8\n",
            "\n",
            "\n",
            "MAE(actual):-  12.622211286169161  fold  9\n",
            "MAE(nearest):-  12.098591549295774  fold  9\n",
            "\n",
            "\n",
            "MAE(actual):-  10.605616047459911  fold  10\n",
            "MAE(nearest):-  11.028169014084508  fold  10\n",
            "\n",
            "\n",
            "MAE(actual):-  10.238427467380275  fold  11\n",
            "MAE(nearest):-  10.549295774647888  fold  11\n",
            "\n",
            "\n",
            "MAE(actual):-  9.890192740405853  fold  12\n",
            "MAE(nearest):-  9.80281690140845  fold  12\n",
            "\n",
            "\n",
            "MAE(actual):-  11.611136978742131  fold  13\n",
            "MAE(nearest):-  11.43661971830986  fold  13\n",
            "\n",
            "\n",
            "MAE(actual):-  12.59619122388092  fold  14\n",
            "MAE(nearest):-  13.098591549295774  fold  14\n",
            "\n",
            "\n",
            "MAE(actual):-  10.4999035954657  fold  15\n",
            "MAE(nearest):-  9.788732394366198  fold  15\n",
            "\n",
            "\n",
            "MAE(actual):-  7.648070964970326  fold  16\n",
            "MAE(nearest):-  7.591549295774648  fold  16\n",
            "\n",
            "\n",
            "MAE(actual):-  10.21408961466815  fold  17\n",
            "MAE(nearest):-  10.028169014084508  fold  17\n",
            "\n",
            "\n",
            "MAE(actual):-  9.424853121193914  fold  18\n",
            "MAE(nearest):-  9.309859154929578  fold  18\n",
            "\n",
            "\n",
            "MAE(actual):-  9.164613284405831  fold  19\n",
            "MAE(nearest):-  8.67605633802817  fold  19\n",
            "\n",
            "\n",
            "MAE(actual):-  9.668974993649416  fold  20\n",
            "MAE(nearest):-  9.647887323943662  fold  20\n",
            "\n",
            "\n",
            "MAE(actual):-  8.772682251048417  fold  21\n",
            "MAE(nearest):-  8.816901408450704  fold  21\n",
            "\n",
            "\n",
            "MAE(actual):-  10.438347053643387  fold  22\n",
            "MAE(nearest):-  10.19718309859155  fold  22\n",
            "\n",
            "\n",
            "MAE(actual):-  11.353726953886607  fold  23\n",
            "MAE(nearest):-  11.52112676056338  fold  23\n",
            "\n",
            "\n",
            "MAE(actual):-  10.724145518108068  fold  24\n",
            "MAE(nearest):-  10.704225352112676  fold  24\n",
            "\n",
            "\n",
            "MAE(actual):-  10.511908207832382  fold  25\n",
            "MAE(nearest):-  10.28169014084507  fold  25\n",
            "\n",
            "\n",
            "OOF MAE(actual):-  10.320434504374173\n",
            "OOF MAE(nearest):-  10.254637436762225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCwcjD73xm4_"
      },
      "source": [
        "## Regression Model 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxfoM-DVwqlg",
        "outputId": "f05d83af-49f6-44e2-e6db-68d4c4b7c897"
      },
      "source": [
        "train_df = train_data.copy()\n",
        "test_df  = test_data.copy()\n",
        "\n",
        "cols2drop = ['PUMP_ID_PHASE','Date','Well_Number','Completion_Type']\n",
        "target_y  = train_df['Volumetric_Capacity'].values\n",
        "train_df  = train_df.drop(cols2drop+['HR','Volumetric_Capacity'],axis=1)\n",
        "test_df   = test_df.drop(cols2drop,axis=1)\n",
        "\n",
        "a         = train_df[train_df.columns].isnull().sum()/train_df.shape[0]\n",
        "cols      = a[a<=0.6].index.tolist()\n",
        "train_df  = train_df[cols]\n",
        "test_df   = test_df[cols]\n",
        "print(train_df.shape,test_df.shape)\n",
        "\n",
        "\n",
        "#### This segment will be used only if we want to make sure the output corresponds to \n",
        "#### a fixed set of volumetric capacity as given in the train data.\n",
        "\n",
        "unique_vals_target = list(set(target_y))\n",
        "def get_nearest_value_possible(value):\n",
        "  '''\n",
        "      Getting target corresponding to nearest value.\n",
        "  '''\n",
        "  abs_distance_dict = {}\n",
        "  for vals in unique_vals_target:\n",
        "    abs_distance_dict[vals] = np.abs(value-vals)\n",
        "  return min(abs_distance_dict, key=abs_distance_dict.get)\n",
        "\n",
        "train     = train_df.values\n",
        "test      = test_df.values\n",
        "train_y   = target_y\n",
        "\n",
        "oof_pred_3               = np.zeros((len(train), ))\n",
        "oof_pred_nearest_3       = np.zeros((len(train), ))\n",
        "y_pred_3                 = np.zeros((len(test), ))\n",
        "n_splits                 = 20\n",
        "kf                       = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (tr_ind, val_ind) in enumerate(kf.split(train, train_y)):\n",
        "  X_train, X_val     = train[tr_ind], train[val_ind]\n",
        "  y_train, y_val     = train_y[tr_ind], train_y[val_ind]\n",
        "\n",
        "  model  = lgb.LGBMRegressor(random_state=42,reg_lambda=5,n_estimators=120,learning_rate=0.095)\n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        "  \n",
        "  val_pred_3                  = model.predict(X_val)\n",
        "  val_pred_nearest_3          = [get_nearest_value_possible(val) for val in val_pred_3]\n",
        "  oof_pred_3[val_ind]         = val_pred_3\n",
        "  oof_pred_nearest_3[val_ind] = val_pred_nearest_3\n",
        "\n",
        "\n",
        "  print('MAE(actual):- ',mean_absolute_error(y_val,val_pred_3),' fold ',fold+1)\n",
        "  print('MAE(nearest):- ',mean_absolute_error(y_val,val_pred_nearest_3),' fold ',fold+1)\n",
        "  print('\\n')\n",
        "  \n",
        "  y_pred_3 += model.predict(test) / (n_splits)\n",
        "\n",
        "print('OOF MAE(actual):- ',(mean_absolute_error(train_y,oof_pred_3)))\n",
        "print('OOF MAE(nearest):- ',(mean_absolute_error(train_y,oof_pred_nearest_3)))\n",
        "y_pred_3_nearest                      = [get_nearest_value_possible(val) for val in y_pred_3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1779, 310) (819, 310)\n",
            "MAE(actual):-  11.395144228104598  fold  1\n",
            "MAE(nearest):-  11.112359550561798  fold  1\n",
            "\n",
            "\n",
            "MAE(actual):-  11.529244742045917  fold  2\n",
            "MAE(nearest):-  11.55056179775281  fold  2\n",
            "\n",
            "\n",
            "MAE(actual):-  10.58312438600045  fold  3\n",
            "MAE(nearest):-  10.584269662921349  fold  3\n",
            "\n",
            "\n",
            "MAE(actual):-  11.895056974754377  fold  4\n",
            "MAE(nearest):-  11.932584269662922  fold  4\n",
            "\n",
            "\n",
            "MAE(actual):-  9.250872728361756  fold  5\n",
            "MAE(nearest):-  9.303370786516854  fold  5\n",
            "\n",
            "\n",
            "MAE(actual):-  8.501605290069929  fold  6\n",
            "MAE(nearest):-  8.52808988764045  fold  6\n",
            "\n",
            "\n",
            "MAE(actual):-  12.556392231600984  fold  7\n",
            "MAE(nearest):-  12.235955056179776  fold  7\n",
            "\n",
            "\n",
            "MAE(actual):-  10.349385413494481  fold  8\n",
            "MAE(nearest):-  10.179775280898877  fold  8\n",
            "\n",
            "\n",
            "MAE(actual):-  10.061239534138839  fold  9\n",
            "MAE(nearest):-  10.123595505617978  fold  9\n",
            "\n",
            "\n",
            "MAE(actual):-  10.438162679256981  fold  10\n",
            "MAE(nearest):-  10.539325842696629  fold  10\n",
            "\n",
            "\n",
            "MAE(actual):-  10.576390808953688  fold  11\n",
            "MAE(nearest):-  10.50561797752809  fold  11\n",
            "\n",
            "\n",
            "MAE(actual):-  11.654577553474567  fold  12\n",
            "MAE(nearest):-  11.539325842696629  fold  12\n",
            "\n",
            "\n",
            "MAE(actual):-  8.518078476767881  fold  13\n",
            "MAE(nearest):-  8.179775280898877  fold  13\n",
            "\n",
            "\n",
            "MAE(actual):-  10.85852690057657  fold  14\n",
            "MAE(nearest):-  10.651685393258427  fold  14\n",
            "\n",
            "\n",
            "MAE(actual):-  8.862760039472768  fold  15\n",
            "MAE(nearest):-  8.707865168539326  fold  15\n",
            "\n",
            "\n",
            "MAE(actual):-  8.90479555854627  fold  16\n",
            "MAE(nearest):-  8.707865168539326  fold  16\n",
            "\n",
            "\n",
            "MAE(actual):-  8.525853326495143  fold  17\n",
            "MAE(nearest):-  8.617977528089888  fold  17\n",
            "\n",
            "\n",
            "MAE(actual):-  10.11379666734453  fold  18\n",
            "MAE(nearest):-  10.134831460674157  fold  18\n",
            "\n",
            "\n",
            "MAE(actual):-  11.862774030957128  fold  19\n",
            "MAE(nearest):-  11.786516853932584  fold  19\n",
            "\n",
            "\n",
            "MAE(actual):-  9.724849995797776  fold  20\n",
            "MAE(nearest):-  9.659090909090908  fold  20\n",
            "\n",
            "\n",
            "OOF MAE(actual):-  10.308459448789941\n",
            "OOF MAE(nearest):-  10.229342327150084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy6lbjBfyMoK"
      },
      "source": [
        "## Regression model 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj5lSEvswqoc",
        "outputId": "52fac4ce-f264-4fc8-a2c0-c697a6254e15"
      },
      "source": [
        "train_df = train_data.copy()\n",
        "test_df  = test_data.copy()\n",
        "\n",
        "cols2drop = ['PUMP_ID_PHASE','Date','Well_Number','Completion_Type']\n",
        "target_y  = train_df['Volumetric_Capacity'].values\n",
        "train_df  = train_df.drop(cols2drop+['HR','Volumetric_Capacity'],axis=1)\n",
        "test_df   = test_df.drop(cols2drop,axis=1)\n",
        "\n",
        "a         = train_df[train_df.columns].isnull().sum()/train_df.shape[0]\n",
        "cols      = a[a<=0.6].index.tolist()\n",
        "train_df  = train_df[cols]\n",
        "test_df   = test_df[cols]\n",
        "print(train_df.shape,test_df.shape)\n",
        "\n",
        "\n",
        "#### This segment will be used only if we want to make sure the output corresponds to \n",
        "#### a fixed set of volumetric capacity as given in the train data.\n",
        "\n",
        "unique_vals_target = list(set(target_y))\n",
        "def get_nearest_value_possible(value):\n",
        "  '''\n",
        "      Getting target corresponding to nearest value.\n",
        "  '''\n",
        "  abs_distance_dict = {}\n",
        "  for vals in unique_vals_target:\n",
        "    abs_distance_dict[vals] = np.abs(value-vals)\n",
        "  return min(abs_distance_dict, key=abs_distance_dict.get)\n",
        "\n",
        "train     = train_df.values\n",
        "test      = test_df.values\n",
        "train_y   = target_y\n",
        "\n",
        "oof_pred_4               = np.zeros((len(train), ))\n",
        "oof_pred_nearest_4       = np.zeros((len(train), ))\n",
        "y_pred_4                 = np.zeros((len(test), ))\n",
        "n_splits                 = 20\n",
        "kf                       = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (tr_ind, val_ind) in enumerate(kf.split(train, train_y)):\n",
        "  X_train, X_val     = train[tr_ind], train[val_ind]\n",
        "  y_train, y_val     = train_y[tr_ind], train_y[val_ind]\n",
        "\n",
        "  model  = lgb.LGBMRegressor(random_state=42,reg_lambda=2,n_estimators=70,learning_rate=0.1)\n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        "  \n",
        "  val_pred_4                  = model.predict(X_val)\n",
        "  val_pred_nearest_4          = [get_nearest_value_possible(val) for val in val_pred_4]\n",
        "  oof_pred_4[val_ind]         = val_pred_4\n",
        "  oof_pred_nearest_4[val_ind] = val_pred_nearest_4\n",
        "\n",
        "\n",
        "  print('MAE(actual):- ',mean_absolute_error(y_val,val_pred_4),' fold ',fold+1)\n",
        "  print('MAE(nearest):- ',mean_absolute_error(y_val,val_pred_nearest_4),' fold ',fold+1)\n",
        "  print('\\n')\n",
        "  \n",
        "  y_pred_4 += model.predict(test) / (n_splits)\n",
        "\n",
        "print('OOF MAE(actual):- ',(mean_absolute_error(train_y,oof_pred_4)))\n",
        "print('OOF MAE(nearest):- ',(mean_absolute_error(train_y,oof_pred_nearest_4)))\n",
        "y_pred_4_nearest                      = [get_nearest_value_possible(val) for val in y_pred_4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1779, 310) (819, 310)\n",
            "MAE(actual):-  11.43256258861148  fold  1\n",
            "MAE(nearest):-  11.415730337078651  fold  1\n",
            "\n",
            "\n",
            "MAE(actual):-  10.289939805783831  fold  2\n",
            "MAE(nearest):-  10.134831460674157  fold  2\n",
            "\n",
            "\n",
            "MAE(actual):-  10.97030722537915  fold  3\n",
            "MAE(nearest):-  10.887640449438202  fold  3\n",
            "\n",
            "\n",
            "MAE(actual):-  11.635595885272505  fold  4\n",
            "MAE(nearest):-  11.584269662921349  fold  4\n",
            "\n",
            "\n",
            "MAE(actual):-  10.006759253862688  fold  5\n",
            "MAE(nearest):-  10.235955056179776  fold  5\n",
            "\n",
            "\n",
            "MAE(actual):-  8.092256376496739  fold  6\n",
            "MAE(nearest):-  8.067415730337078  fold  6\n",
            "\n",
            "\n",
            "MAE(actual):-  12.656343545121945  fold  7\n",
            "MAE(nearest):-  12.561797752808989  fold  7\n",
            "\n",
            "\n",
            "MAE(actual):-  10.320370817981  fold  8\n",
            "MAE(nearest):-  10.01123595505618  fold  8\n",
            "\n",
            "\n",
            "MAE(actual):-  10.216996478511115  fold  9\n",
            "MAE(nearest):-  10.191011235955056  fold  9\n",
            "\n",
            "\n",
            "MAE(actual):-  10.541343462490815  fold  10\n",
            "MAE(nearest):-  10.359550561797754  fold  10\n",
            "\n",
            "\n",
            "MAE(actual):-  10.4417843049313  fold  11\n",
            "MAE(nearest):-  10.179775280898877  fold  11\n",
            "\n",
            "\n",
            "MAE(actual):-  11.122575144202417  fold  12\n",
            "MAE(nearest):-  10.9438202247191  fold  12\n",
            "\n",
            "\n",
            "MAE(actual):-  8.82017581738925  fold  13\n",
            "MAE(nearest):-  8.9438202247191  fold  13\n",
            "\n",
            "\n",
            "MAE(actual):-  10.503725753198799  fold  14\n",
            "MAE(nearest):-  10.359550561797754  fold  14\n",
            "\n",
            "\n",
            "MAE(actual):-  9.26556878356543  fold  15\n",
            "MAE(nearest):-  9.337078651685394  fold  15\n",
            "\n",
            "\n",
            "MAE(actual):-  9.428065089608753  fold  16\n",
            "MAE(nearest):-  9.370786516853933  fold  16\n",
            "\n",
            "\n",
            "MAE(actual):-  8.491996153088369  fold  17\n",
            "MAE(nearest):-  8.415730337078651  fold  17\n",
            "\n",
            "\n",
            "MAE(actual):-  9.64989379255104  fold  18\n",
            "MAE(nearest):-  9.561797752808989  fold  18\n",
            "\n",
            "\n",
            "MAE(actual):-  11.88326189065889  fold  19\n",
            "MAE(nearest):-  11.651685393258427  fold  19\n",
            "\n",
            "\n",
            "MAE(actual):-  9.762286716534357  fold  20\n",
            "MAE(nearest):-  9.659090909090908  fold  20\n",
            "\n",
            "\n",
            "OOF MAE(actual):-  10.276879541354589\n",
            "OOF MAE(nearest):-  10.193929173693085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmrrTZBuywiL"
      },
      "source": [
        "## Regression Model 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhVCd8N9wqrQ",
        "outputId": "2ab70a4a-ffc1-4b44-ec00-dd5da156f014"
      },
      "source": [
        "train_df = train_data.copy()\n",
        "test_df  = test_data.copy()\n",
        "\n",
        "cols2drop = ['PUMP_ID_PHASE','Date','Well_Number','Completion_Type']\n",
        "target_y  = train_df['Volumetric_Capacity'].values\n",
        "train_df  = train_df.drop(cols2drop+['HR','Volumetric_Capacity'],axis=1)\n",
        "test_df   = test_df.drop(cols2drop,axis=1)\n",
        "\n",
        "a         = train_df[train_df.columns].isnull().sum()/train_df.shape[0]\n",
        "cols      = a[a<=0.6].index.tolist()\n",
        "train_df  = train_df[cols]\n",
        "test_df   = test_df[cols]\n",
        "print(train_df.shape,test_df.shape)\n",
        "\n",
        "\n",
        "#### This segment will be used only if we want to make sure the output corresponds to \n",
        "#### a fixed set of volumetric capacity as given in the train data.\n",
        "\n",
        "unique_vals_target = list(set(target_y))\n",
        "def get_nearest_value_possible(value):\n",
        "  '''\n",
        "      Getting target corresponding to nearest value.\n",
        "  '''\n",
        "  abs_distance_dict = {}\n",
        "  for vals in unique_vals_target:\n",
        "    abs_distance_dict[vals] = np.abs(value-vals)\n",
        "  return min(abs_distance_dict, key=abs_distance_dict.get)\n",
        "\n",
        "train     = train_df.values\n",
        "test      = test_df.values\n",
        "train_y   = target_y\n",
        "\n",
        "oof_pred_5               = np.zeros((len(train), ))\n",
        "oof_pred_nearest_5       = np.zeros((len(train), ))\n",
        "y_pred_5                 = np.zeros((len(test), ))\n",
        "n_splits                 = 20\n",
        "kf                       = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (tr_ind, val_ind) in enumerate(kf.split(train, train_y)):\n",
        "  X_train, X_val     = train[tr_ind], train[val_ind]\n",
        "  y_train, y_val     = train_y[tr_ind], train_y[val_ind]\n",
        "\n",
        "  model  = lgb.LGBMRegressor(random_state=42,reg_lambda=4,n_estimators=85,learning_rate=0.1,min_split_gain=0.7,num_leaves=64)\n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        "  \n",
        "  val_pred_5                  = model.predict(X_val)\n",
        "  val_pred_nearest_5          = [get_nearest_value_possible(val) for val in val_pred_5]\n",
        "  oof_pred_5[val_ind]         = val_pred_5\n",
        "  oof_pred_nearest_5[val_ind] = val_pred_nearest_5\n",
        "\n",
        "\n",
        "  print('MAE(actual):- ',mean_absolute_error(y_val,val_pred_5),' fold ',fold+1)\n",
        "  print('MAE(nearest):- ',mean_absolute_error(y_val,val_pred_nearest_5),' fold ',fold+1)\n",
        "  print('\\n')\n",
        "  \n",
        "  y_pred_5 += model.predict(test) / (n_splits)\n",
        "\n",
        "print('OOF MAE(actual):- ',(mean_absolute_error(train_y,oof_pred_5)))\n",
        "print('OOF MAE(nearest):- ',(mean_absolute_error(train_y,oof_pred_nearest_5)))\n",
        "y_pred_5_nearest                      = [get_nearest_value_possible(val) for val in y_pred_5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1779, 310) (819, 310)\n",
            "MAE(actual):-  11.14234637529691  fold  1\n",
            "MAE(nearest):-  11.03370786516854  fold  1\n",
            "\n",
            "\n",
            "MAE(actual):-  11.355056998271237  fold  2\n",
            "MAE(nearest):-  11.269662921348315  fold  2\n",
            "\n",
            "\n",
            "MAE(actual):-  10.791457536259037  fold  3\n",
            "MAE(nearest):-  10.96629213483146  fold  3\n",
            "\n",
            "\n",
            "MAE(actual):-  11.240879493617667  fold  4\n",
            "MAE(nearest):-  11.179775280898877  fold  4\n",
            "\n",
            "\n",
            "MAE(actual):-  9.561029400232767  fold  5\n",
            "MAE(nearest):-  9.707865168539326  fold  5\n",
            "\n",
            "\n",
            "MAE(actual):-  8.645751821890231  fold  6\n",
            "MAE(nearest):-  8.629213483146067  fold  6\n",
            "\n",
            "\n",
            "MAE(actual):-  12.698895541942777  fold  7\n",
            "MAE(nearest):-  12.606741573033707  fold  7\n",
            "\n",
            "\n",
            "MAE(actual):-  10.159406383186049  fold  8\n",
            "MAE(nearest):-  10.168539325842696  fold  8\n",
            "\n",
            "\n",
            "MAE(actual):-  10.043956061060003  fold  9\n",
            "MAE(nearest):-  10.067415730337078  fold  9\n",
            "\n",
            "\n",
            "MAE(actual):-  10.243767416783394  fold  10\n",
            "MAE(nearest):-  10.01123595505618  fold  10\n",
            "\n",
            "\n",
            "MAE(actual):-  10.509478673971023  fold  11\n",
            "MAE(nearest):-  10.44943820224719  fold  11\n",
            "\n",
            "\n",
            "MAE(actual):-  10.858798798214117  fold  12\n",
            "MAE(nearest):-  10.674157303370787  fold  12\n",
            "\n",
            "\n",
            "MAE(actual):-  8.914828414990373  fold  13\n",
            "MAE(nearest):-  8.685393258426966  fold  13\n",
            "\n",
            "\n",
            "MAE(actual):-  11.012972253244808  fold  14\n",
            "MAE(nearest):-  11.07865168539326  fold  14\n",
            "\n",
            "\n",
            "MAE(actual):-  9.230703737378025  fold  15\n",
            "MAE(nearest):-  9.0561797752809  fold  15\n",
            "\n",
            "\n",
            "MAE(actual):-  9.001709945871456  fold  16\n",
            "MAE(nearest):-  8.820224719101123  fold  16\n",
            "\n",
            "\n",
            "MAE(actual):-  8.563524537840808  fold  17\n",
            "MAE(nearest):-  8.426966292134832  fold  17\n",
            "\n",
            "\n",
            "MAE(actual):-  10.125381636289537  fold  18\n",
            "MAE(nearest):-  9.97752808988764  fold  18\n",
            "\n",
            "\n",
            "MAE(actual):-  11.984506019187329  fold  19\n",
            "MAE(nearest):-  11.932584269662922  fold  19\n",
            "\n",
            "\n",
            "MAE(actual):-  9.786153545885297  fold  20\n",
            "MAE(nearest):-  9.647727272727273  fold  20\n",
            "\n",
            "\n",
            "OOF MAE(actual):-  10.293815432877942\n",
            "OOF MAE(nearest):-  10.219786396852165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2bV0SY50e2p"
      },
      "source": [
        "## Building meta estimator based on 5 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "6PjWUeo1wquA",
        "outputId": "01967be5-51d7-40d7-d834-61a6a6926338"
      },
      "source": [
        "meta_train_df = pd.DataFrame(oof_pred_nearest_1,columns=['Model_1_rounded'])\n",
        "meta_train_df['Model1']          = oof_pred_1\n",
        "\n",
        "meta_train_df['Model_2_rounded'] = oof_pred_nearest_2\n",
        "meta_train_df['Model2']          = oof_pred_2\n",
        "\n",
        "meta_train_df['Model_3_rounded'] = oof_pred_nearest_3\n",
        "meta_train_df['Model3']          = oof_pred_3\n",
        "\n",
        "meta_train_df['Model_4_rounded'] = oof_pred_nearest_4\n",
        "meta_train_df['Model4']          = oof_pred_4\n",
        "\n",
        "meta_train_df['Model_5_rounded'] = oof_pred_nearest_5\n",
        "meta_train_df['Model5']          = oof_pred_5\n",
        "\n",
        "meta_train_df['predictions'] = target_y\n",
        "meta_train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_1_rounded</th>\n",
              "      <th>Model1</th>\n",
              "      <th>Model_2_rounded</th>\n",
              "      <th>Model2</th>\n",
              "      <th>Model_3_rounded</th>\n",
              "      <th>Model3</th>\n",
              "      <th>Model_4_rounded</th>\n",
              "      <th>Model4</th>\n",
              "      <th>Model_5_rounded</th>\n",
              "      <th>Model5</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23.0</td>\n",
              "      <td>22.589578</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.513345</td>\n",
              "      <td>22.0</td>\n",
              "      <td>21.642098</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.636059</td>\n",
              "      <td>27.0</td>\n",
              "      <td>26.148603</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30.0</td>\n",
              "      <td>28.713606</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.081619</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.399080</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.442301</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.124243</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34.0</td>\n",
              "      <td>33.838661</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.223275</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.765988</td>\n",
              "      <td>33.0</td>\n",
              "      <td>32.659530</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.643641</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40.0</td>\n",
              "      <td>39.724618</td>\n",
              "      <td>38.0</td>\n",
              "      <td>38.339837</td>\n",
              "      <td>40.0</td>\n",
              "      <td>39.230205</td>\n",
              "      <td>40.0</td>\n",
              "      <td>39.477287</td>\n",
              "      <td>42.0</td>\n",
              "      <td>41.693242</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23.0</td>\n",
              "      <td>22.538562</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.729805</td>\n",
              "      <td>23.0</td>\n",
              "      <td>22.685801</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.965227</td>\n",
              "      <td>30.0</td>\n",
              "      <td>29.160956</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1774</th>\n",
              "      <td>35.0</td>\n",
              "      <td>34.760135</td>\n",
              "      <td>33.0</td>\n",
              "      <td>32.860413</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.336018</td>\n",
              "      <td>38.0</td>\n",
              "      <td>37.379422</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33.160091</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1775</th>\n",
              "      <td>24.0</td>\n",
              "      <td>24.401393</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.039997</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.851944</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.727127</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.359318</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1776</th>\n",
              "      <td>14.0</td>\n",
              "      <td>13.848111</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.341234</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.958283</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.876858</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.282738</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1777</th>\n",
              "      <td>13.0</td>\n",
              "      <td>11.748397</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.686304</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.870914</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.374368</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.090929</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1778</th>\n",
              "      <td>30.0</td>\n",
              "      <td>30.031021</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33.168036</td>\n",
              "      <td>27.0</td>\n",
              "      <td>26.489285</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.899997</td>\n",
              "      <td>30.0</td>\n",
              "      <td>29.641510</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1779 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Model_1_rounded     Model1  ...     Model5  predictions\n",
              "0                23.0  22.589578  ...  26.148603         33.0\n",
              "1                30.0  28.713606  ...  30.124243         40.0\n",
              "2                34.0  33.838661  ...  31.643641         33.0\n",
              "3                40.0  39.724618  ...  41.693242         40.0\n",
              "4                23.0  22.538562  ...  29.160956         33.0\n",
              "...               ...        ...  ...        ...          ...\n",
              "1774             35.0  34.760135  ...  33.160091         33.0\n",
              "1775             24.0  24.401393  ...  30.359318         33.0\n",
              "1776             14.0  13.848111  ...  13.282738          8.0\n",
              "1777             13.0  11.748397  ...  14.090929         13.0\n",
              "1778             30.0  30.031021  ...  29.641510         23.0\n",
              "\n",
              "[1779 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "zPpnvR1fwqw9",
        "outputId": "ad8038ec-3706-4819-c06b-770ec40dac80"
      },
      "source": [
        "meta_test_df = pd.DataFrame(y_pred_1_nearest,columns=['Model_1_rounded'])\n",
        "meta_test_df['Model1'] = y_pred_1\n",
        "\n",
        "meta_test_df['Model_2_rounded'] = y_pred_2_nearest\n",
        "meta_test_df['Model2'] = y_pred_2\n",
        "\n",
        "meta_test_df['Model_3_rounded'] = y_pred_3_nearest\n",
        "meta_test_df['Model3'] = y_pred_3\n",
        "\n",
        "meta_test_df['Model_4_rounded'] = y_pred_4_nearest\n",
        "meta_test_df['Model4'] = y_pred_4\n",
        "\n",
        "meta_test_df['Model_5_rounded'] = y_pred_5_nearest\n",
        "meta_test_df['Model5'] = y_pred_5\n",
        "\n",
        "meta_test_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_1_rounded</th>\n",
              "      <th>Model1</th>\n",
              "      <th>Model_2_rounded</th>\n",
              "      <th>Model2</th>\n",
              "      <th>Model_3_rounded</th>\n",
              "      <th>Model3</th>\n",
              "      <th>Model_4_rounded</th>\n",
              "      <th>Model4</th>\n",
              "      <th>Model_5_rounded</th>\n",
              "      <th>Model5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32.0</td>\n",
              "      <td>31.511952</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.717288</td>\n",
              "      <td>32.0</td>\n",
              "      <td>32.169069</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.196630</td>\n",
              "      <td>34.0</td>\n",
              "      <td>34.068797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.0</td>\n",
              "      <td>18.595537</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.537480</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.210186</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.771103</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.490034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.0</td>\n",
              "      <td>17.126426</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.514147</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.130394</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.743207</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.241458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24.0</td>\n",
              "      <td>24.036883</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.863544</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23.273367</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.760759</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.904662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.0</td>\n",
              "      <td>19.939279</td>\n",
              "      <td>22.0</td>\n",
              "      <td>21.585843</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.378041</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.930252</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.466718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814</th>\n",
              "      <td>22.0</td>\n",
              "      <td>21.850285</td>\n",
              "      <td>23.0</td>\n",
              "      <td>22.666561</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.146739</td>\n",
              "      <td>22.0</td>\n",
              "      <td>21.646112</td>\n",
              "      <td>23.0</td>\n",
              "      <td>22.946442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>23.0</td>\n",
              "      <td>22.865520</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.195187</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.307984</td>\n",
              "      <td>23.0</td>\n",
              "      <td>22.627338</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.522002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>30.0</td>\n",
              "      <td>30.492347</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.727879</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.929486</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.136113</td>\n",
              "      <td>33.0</td>\n",
              "      <td>32.919980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>24.0</td>\n",
              "      <td>24.128590</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.937842</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.828542</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.711077</td>\n",
              "      <td>27.0</td>\n",
              "      <td>26.678236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>818</th>\n",
              "      <td>32.0</td>\n",
              "      <td>32.233248</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.422088</td>\n",
              "      <td>32.0</td>\n",
              "      <td>32.330197</td>\n",
              "      <td>33.0</td>\n",
              "      <td>32.559380</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.325498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>819 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Model_1_rounded     Model1  ...  Model_5_rounded     Model5\n",
              "0               32.0  31.511952  ...             34.0  34.068797\n",
              "1               20.0  18.595537  ...             16.0  17.490034\n",
              "2               16.0  17.126426  ...             15.0  15.241458\n",
              "3               24.0  24.036883  ...             24.0  23.904662\n",
              "4               20.0  19.939279  ...             20.0  19.466718\n",
              "..               ...        ...  ...              ...        ...\n",
              "814             22.0  21.850285  ...             23.0  22.946442\n",
              "815             23.0  22.865520  ...             24.0  23.522002\n",
              "816             30.0  30.492347  ...             33.0  32.919980\n",
              "817             24.0  24.128590  ...             27.0  26.678236\n",
              "818             32.0  32.233248  ...             32.0  31.325498\n",
              "\n",
              "[819 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONXUmgvnwqz4",
        "outputId": "9a8334a6-4009-4f77-c215-3f7dce453bc3"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "train_df = meta_train_df\n",
        "test_df  = meta_test_df\n",
        "\n",
        "target_y  = train_df['predictions'].values\n",
        "train_df  = train_df.drop(['predictions'],axis=1)\n",
        "\n",
        "print(train_df.shape,test_df.shape)\n",
        "\n",
        "\n",
        "#### This segment will be used only if we want to make sure the output corresponds to \n",
        "#### a fixed set of volumetric capacity as given in the train data.\n",
        "\n",
        "unique_vals_target = list(set(target_y))\n",
        "def get_nearest_value_possible(value):\n",
        "  '''\n",
        "      Getting target corresponding to nearest value.\n",
        "  '''\n",
        "  abs_distance_dict = {}\n",
        "  for vals in unique_vals_target:\n",
        "    abs_distance_dict[vals] = np.abs(value-vals)\n",
        "  return min(abs_distance_dict, key=abs_distance_dict.get)\n",
        "\n",
        "train     = train_df.values\n",
        "test      = test_df.values\n",
        "train_y   = target_y\n",
        "\n",
        "oof_pred               = np.zeros((len(train), ))\n",
        "oof_pred_nearest       = np.zeros((len(train), ))\n",
        "y_pred                 = np.zeros((len(test), ))\n",
        "n_splits               = 20\n",
        "kf                     = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (tr_ind, val_ind) in enumerate(kf.split(train, train_y)):\n",
        "  X_train, X_val     = train[tr_ind], train[val_ind]\n",
        "  y_train, y_val     = train_y[tr_ind], train_y[val_ind]\n",
        "\n",
        "  model  = ElasticNet(random_state=42,alpha = 1,l1_ratio=0.5,max_iter=1000,selection='random')\n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        "  \n",
        "  val_pred                  = model.predict(X_val)\n",
        "  val_pred_nearest          = [get_nearest_value_possible(val) for val in val_pred]\n",
        "  oof_pred[val_ind]         = val_pred\n",
        "  oof_pred_nearest[val_ind] = val_pred_nearest\n",
        "\n",
        "\n",
        "  print('MAE(actual):- ',mean_absolute_error(y_val,val_pred),' fold ',fold+1)\n",
        "  print('MAE(nearest):- ',mean_absolute_error(y_val,val_pred_nearest),' fold ',fold+1)\n",
        "  print('\\n')\n",
        "  \n",
        "  y_pred += model.predict(test) / (n_splits)\n",
        "\n",
        "print('OOF MAE(actual):- ',(mean_absolute_error(train_y,oof_pred)))\n",
        "print('OOF MAE(nearest):- ',(mean_absolute_error(train_y,oof_pred_nearest)))\n",
        "y_pred                      = [get_nearest_value_possible(val) for val in y_pred]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1779, 10) (819, 10)\n",
            "MAE(actual):-  11.088227602515747  fold  1\n",
            "MAE(nearest):-  10.910112359550562  fold  1\n",
            "\n",
            "\n",
            "MAE(actual):-  11.018739324695796  fold  2\n",
            "MAE(nearest):-  10.876404494382022  fold  2\n",
            "\n",
            "\n",
            "MAE(actual):-  10.644863369329695  fold  3\n",
            "MAE(nearest):-  10.49438202247191  fold  3\n",
            "\n",
            "\n",
            "MAE(actual):-  11.22547578150398  fold  4\n",
            "MAE(nearest):-  11.235955056179776  fold  4\n",
            "\n",
            "\n",
            "MAE(actual):-  9.712081882250574  fold  5\n",
            "MAE(nearest):-  9.617977528089888  fold  5\n",
            "\n",
            "\n",
            "MAE(actual):-  8.25123792842528  fold  6\n",
            "MAE(nearest):-  8.168539325842696  fold  6\n",
            "\n",
            "\n",
            "MAE(actual):-  12.473143494444724  fold  7\n",
            "MAE(nearest):-  12.280898876404494  fold  7\n",
            "\n",
            "\n",
            "MAE(actual):-  10.199415962585679  fold  8\n",
            "MAE(nearest):-  9.898876404494382  fold  8\n",
            "\n",
            "\n",
            "MAE(actual):-  10.132742392987609  fold  9\n",
            "MAE(nearest):-  10.134831460674157  fold  9\n",
            "\n",
            "\n",
            "MAE(actual):-  10.21366630180158  fold  10\n",
            "MAE(nearest):-  10.044943820224718  fold  10\n",
            "\n",
            "\n",
            "MAE(actual):-  10.816029555231164  fold  11\n",
            "MAE(nearest):-  10.674157303370787  fold  11\n",
            "\n",
            "\n",
            "MAE(actual):-  10.976372431666494  fold  12\n",
            "MAE(nearest):-  10.393258426966293  fold  12\n",
            "\n",
            "\n",
            "MAE(actual):-  8.582212533121181  fold  13\n",
            "MAE(nearest):-  8.325842696629213  fold  13\n",
            "\n",
            "\n",
            "MAE(actual):-  10.378197992725266  fold  14\n",
            "MAE(nearest):-  10.213483146067416  fold  14\n",
            "\n",
            "\n",
            "MAE(actual):-  9.030164410443376  fold  15\n",
            "MAE(nearest):-  9.03370786516854  fold  15\n",
            "\n",
            "\n",
            "MAE(actual):-  9.072098863509552  fold  16\n",
            "MAE(nearest):-  9.202247191011235  fold  16\n",
            "\n",
            "\n",
            "MAE(actual):-  8.45368060064454  fold  17\n",
            "MAE(nearest):-  8.314606741573034  fold  17\n",
            "\n",
            "\n",
            "MAE(actual):-  9.81020373281342  fold  18\n",
            "MAE(nearest):-  9.696629213483146  fold  18\n",
            "\n",
            "\n",
            "MAE(actual):-  11.6429046415474  fold  19\n",
            "MAE(nearest):-  11.730337078651685  fold  19\n",
            "\n",
            "\n",
            "MAE(actual):-  9.67556930216433  fold  20\n",
            "MAE(nearest):-  9.511363636363637  fold  20\n",
            "\n",
            "\n",
            "OOF MAE(actual):-  10.170129247886505\n",
            "OOF MAE(nearest):-  10.038223721191681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60LAog-mRuMB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk7NzXDk8juf"
      },
      "source": [
        "## Output preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t2L4tGmSA-W",
        "outputId": "92256ff2-1349-47ca-d217-334b28f9b49f"
      },
      "source": [
        "sub_df                        = pd.DataFrame(columns=['Volumetric_Capacity'])\n",
        "sub_df['Volumetric_Capacity'] = y_pred\n",
        "sub_df['Volumetric_Capacity'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    819.000000\n",
              "mean      38.637363\n",
              "std       23.363276\n",
              "min        8.000000\n",
              "25%       23.000000\n",
              "50%       32.000000\n",
              "75%       45.000000\n",
              "max      150.000000\n",
              "Name: Volumetric_Capacity, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9747KQL3SBBJ"
      },
      "source": [
        "test_df               = test_data.copy()\n",
        "sub_df['pump_id']     = test_df['PUMP_ID_PHASE']\n",
        "sub_df['Date']        = test_df['Date']\n",
        "sub_df['Well_Number'] = test_df['Well_Number']\n",
        "output_df_reg       = sub_df[['pump_id','Well_Number','Date','Volumetric_Capacity']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKDBwgsJUbBd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "dee36014-e3b8-451c-e0c0-9aa8bf5f42bf"
      },
      "source": [
        "output_df_reg.to_csv('nearest_rectified_meta_data_elastc_net.csv',index=False)\n",
        "output_df_reg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pump_id</th>\n",
              "      <th>Well_Number</th>\n",
              "      <th>Date</th>\n",
              "      <th>Volumetric_Capacity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.0</td>\n",
              "      <td>AGB005</td>\n",
              "      <td>2019-07-30</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.0</td>\n",
              "      <td>AGQ001</td>\n",
              "      <td>2014-06-12</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>AGQ001</td>\n",
              "      <td>2017-12-11</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33.0</td>\n",
              "      <td>AGQ007</td>\n",
              "      <td>2014-08-22</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34.0</td>\n",
              "      <td>AGQ007</td>\n",
              "      <td>2017-05-08</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814</th>\n",
              "      <td>3720.0</td>\n",
              "      <td>ZUP197</td>\n",
              "      <td>2018-05-16</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>3730.0</td>\n",
              "      <td>ZUP201</td>\n",
              "      <td>2018-05-18</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>3743.0</td>\n",
              "      <td>ZUP207</td>\n",
              "      <td>2019-03-02</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>3744.0</td>\n",
              "      <td>ZUP207</td>\n",
              "      <td>2019-07-27</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>818</th>\n",
              "      <td>3751.0</td>\n",
              "      <td>ZUP210</td>\n",
              "      <td>2020-04-27</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>819 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     pump_id Well_Number        Date  Volumetric_Capacity\n",
              "0        9.0      AGB005  2019-07-30                 32.0\n",
              "1       13.0      AGQ001  2014-06-12                 20.0\n",
              "2       14.0      AGQ001  2017-12-11                 16.0\n",
              "3       33.0      AGQ007  2014-08-22                 24.0\n",
              "4       34.0      AGQ007  2017-05-08                 20.0\n",
              "..       ...         ...         ...                  ...\n",
              "814   3720.0      ZUP197  2018-05-16                 22.0\n",
              "815   3730.0      ZUP201  2018-05-18                 23.0\n",
              "816   3743.0      ZUP207  2019-03-02                 32.0\n",
              "817   3744.0      ZUP207  2019-07-27                 24.0\n",
              "818   3751.0      ZUP210  2020-04-27                 32.0\n",
              "\n",
              "[819 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3soVmIp8cZP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}